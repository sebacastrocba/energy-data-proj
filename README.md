# An√°lisis de Precios de Combustibles en Argentina

![CI](https://github.com/sebacastrocba/energy-data-proj/workflows/CI/badge.svg)
[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/release/python-3120/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## Descripci√≥n del Proyecto

Este proyecto implementa un pipeline de datos (ETL) completo que extrae, transforma y carga informaci√≥n sobre precios de combustibles en Argentina, combin√°ndola con datos del precio internacional del petr√≥leo Brent y cotizaciones USD/ARS (oficial y blue). El objetivo es analizar la correlaci√≥n entre los precios locales, el mercado internacional de petr√≥leo y la evoluci√≥n del tipo de cambio.

**Caso de uso:** Permite a analistas y tomadores de decisiones entender c√≥mo fluct√∫an los precios de combustibles en Argentina en relaci√≥n con el precio del petr√≥leo Brent y el tipo de cambio, identificando patrones temporales y geogr√°ficos.

## Caracter√≠sticas Principales

- ‚úÖ **Extracci√≥n de datos** de m√∫ltiples fuentes (Secretar√≠a de Energ√≠a, Yahoo Finance, Bluelytics API)
- ‚úÖ **Transformaci√≥n y limpieza** de datos con pandas y numpy
- ‚úÖ **Carga a PostgreSQL** con Docker Compose (schemas staging y analytics)
- ‚úÖ **Orquestaci√≥n con Apache Airflow** para automatizaci√≥n del pipeline
- ‚úÖ **An√°lisis exploratorio** con Jupyter notebooks
- ‚úÖ **Tests automatizados** con pytest y pytest-cov
- ‚úÖ **Type checking** con mypy
- ‚úÖ **Gesti√≥n de dependencias** con Poetry
- ‚úÖ **Context managers** para manejo seguro de conexiones DB

## üöÄ Inicio R√°pido

### Requisitos Previos

- Docker y Docker Compose instalados
- Python 3.12+
- Poetry (recomendado) o pip

### Instalaci√≥n

```bash
# 1. Clonar el repositorio
git clone https://github.com/sebacastrocba/energy-data-proj.git
cd fuel_price_project

# 2. Crear archivo de configuraci√≥n
cp .env.example .env
# Edita .env si necesitas cambiar credenciales

# 3. Levantar PostgreSQL con Docker
docker-compose up -d

# 4. Instalar dependencias Python con Poetry
poetry install
```

El archivo `sql/init.sql` se ejecuta autom√°ticamente al crear el contenedor de PostgreSQL por primera vez, inicializando los schemas y tablas necesarias.

## üìä Uso del Pipeline

### Pipeline ETL Paso a Paso

El pipeline ETL se ejecuta en tres pasos secuenciales:

**Paso 1: Extracci√≥n** - Descarga datos de APIs y los guarda en `data/raw/` como CSV
```bash
poetry run python src/fuel_price/extract.py
```
- Descarga precios de Brent desde Yahoo Finance
- Descarga cotizaciones USD/ARS desde Bluelytics API
- Extrae datos de combustibles de la Secretar√≠a de Energ√≠a
- Guarda archivos CSV en `data/raw/`

**Paso 2: Transformaci√≥n** - Lee CSVs, limpia y agrega datos, genera Parquets en `data/processed/`
```bash
poetry run python src/fuel_price/transform.py
```
- Lee archivos CSV de `data/raw/`
- Limpia y valida datos
- Genera agregaciones mensuales
- Guarda archivos Parquet en `data/processed/`

**Paso 3: Carga** - Lee Parquets y carga a PostgreSQL
```bash
poetry run python src/fuel_price/load.py
```
- Lee archivos Parquet de `data/processed/`
- Carga datos a tablas `staging.*` (datos limpios)
- Carga agregaciones a tablas `analytics.*` (datos mensuales)

### Usar como Librer√≠a

```python
from fuel_price.extract import extract_brent_prices, extract_dolar_bluelytics, extract_fuel_prices
from fuel_price.transform import (
    clean_brent_price, 
    agg_brent_price_for_analytics,
    clean_fuel_price, 
    agg_fuel_price_for_analytics,
    clean_dollar_price,
    agg_dollar_price_for_analytics
)
from fuel_price.load import (
    load_brent_to_staging, 
    load_brent_to_analytics,
    load_fuel_to_staging,
    load_fuel_to_analytics,
    load_dollar_to_staging,
    load_dollar_to_analytics
)

# Extraer
brent_raw = extract_brent_prices()
fuel_raw = extract_fuel_prices()
usd_raw = extract_dolar_bluelytics()

# Transformar
brent_clean = clean_brent_price(brent_raw)
brent_analytics = agg_brent_price_for_analytics(brent_clean)

# Cargar a PostgreSQL
load_brent_to_staging(brent_clean, truncate=True)
load_brent_to_analytics(brent_analytics, truncate=True)
```


## üóÇÔ∏è Estructura de Base de Datos

### Schemas Creados

- **`staging`**: Datos crudos o m√≠nimamente procesados
- **`analytics`**: Datos transformados y agregados a nivel mensual

### Tablas Staging

| Tabla | Descripci√≥n | Campos Principales |
|-------|-------------|-------------------|
| `staging.brent_price` | Precios diarios del petr√≥leo Brent | `date`, `brent_price` |
| `staging.fuel_prices` | Precios de combustibles por estaci√≥n | `periodo`, `provincia`, `producto`, `precio_surtidor`, `volumen` |
| `staging.usd_ars_rates` | Cotizaci√≥n USD/ARS (oficial y blue) | `date`, `source`, `value_buy`, `value_sell` |

### Tablas Analytics (Agregaciones Mensuales)

| Tabla | Descripci√≥n | Agregaciones |
|-------|-------------|--------------|
| `analytics.brent_price_monthly` | Brent agregado mensualmente | Promedio, min, max, desviaci√≥n est√°ndar |
| `analytics.fuel_prices_monthly` | Combustibles por mes/provincia/producto | Promedio ponderado por volumen |
| `analytics.usd_ars_rates_monthly` | USD/ARS mensual con brecha cambiaria | Promedio blue, oficial, brecha % |

## üîç Explorar la Base de Datos

### Conectar con psql

```bash
# Usando las credenciales por defecto
PGPASSWORD=fuel_password psql -h localhost -p 5432 -U fuel_user -d fuel_prices_db
```

### Consultas √ötiles

```sql
-- Ver schemas
\dn

-- Ver tablas de staging
\dt staging.*

-- Ver tablas de analytics
\dt analytics.*

-- Ver estructura de una tabla
\d staging.brent_price

-- Consultar √∫ltimos precios de Brent
SELECT * FROM staging.brent_price ORDER BY date DESC LIMIT 10;

-- Ver agregaci√≥n mensual de combustibles por provincia
SELECT year, month, provincia, producto, avg_price 
FROM analytics.fuel_prices_monthly 
WHERE year = 2024 AND provincia = 'BUENOS AIRES'
ORDER BY month DESC, producto
LIMIT 20;

-- Comparar brecha cambiaria mensual
SELECT year, month, avg_blue, avg_oficial, brecha_pct
FROM analytics.usd_ars_rates_monthly
ORDER BY year DESC, month DESC
LIMIT 12;
```

## üê≥ Comandos Docker √ötiles

```bash
# Ver estado del contenedor
docker-compose ps

# Ver logs
docker-compose logs -f

# Detener (datos se mantienen)
docker-compose stop

# Reiniciar
docker-compose restart

# Eliminar todo (BORRA DATOS)
docker-compose down -v
```

## üß™ Testing

El proyecto incluye tests automatizados para las funciones de extracci√≥n y transformaci√≥n.

### Ejecutar todos los tests

```bash
poetry run pytest
```

### Ejecutar tests con cobertura

```bash
poetry run pytest --cov=src/fuel_price --cov-report=html
```

El reporte HTML se genera en `htmlcov/index.html`.

### Ejecutar tests espec√≠ficos

```bash
# Solo tests de extracci√≥n
poetry run pytest tests/test_extract.py

# Solo tests de transformaci√≥n
poetry run pytest tests/test_transform.py

# Ejecutar un test espec√≠fico
poetry run pytest tests/test_transform.py::test_agg_brent_price_calculates_monthly_average
```

### Verificaci√≥n de tipos con mypy

```bash
poetry run mypy src/fuel_price
```

## üìÅ Estructura del Proyecto

```
fuel_price_project/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ fuel_price/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ config.py            # Configuraci√≥n global y constantes
‚îÇ       ‚îú‚îÄ‚îÄ extract.py           # Extracci√≥n de datos de APIs
‚îÇ       ‚îú‚îÄ‚îÄ transform.py         # Transformaci√≥n y limpieza de datos
‚îÇ       ‚îú‚îÄ‚îÄ load.py              # Carga a PostgreSQL con context managers
‚îÇ       ‚îî‚îÄ‚îÄ get_price_data_SE.py # Extractor de datos de Secretar√≠a de Energ√≠a
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_extract.py          # Tests de extracci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ test_transform.py        # Tests de transformaci√≥n
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ 00_analisis_exploratorio.ipynb  # An√°lisis exploratorio de datos
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îî‚îÄ‚îÄ init.sql                 # Schema SQL (staging + analytics)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                     # Datos originales (gitignored)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ brent_prices.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ usd_ars_bluelytics.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ precios_eess_completo.csv
‚îÇ   ‚îî‚îÄ‚îÄ processed/               # Datos procesados (gitignored)
‚îú‚îÄ‚îÄ logs/                        # Logs del sistema (gitignored)
‚îú‚îÄ‚îÄ docs/                        # Documentaci√≥n adicional
‚îú‚îÄ‚îÄ dags/                        # Para futura integraci√≥n con Airflow
‚îú‚îÄ‚îÄ docker-compose.yml           # Configuraci√≥n de PostgreSQL
‚îú‚îÄ‚îÄ pyproject.toml               # Configuraci√≥n de Poetry y dependencias
‚îú‚îÄ‚îÄ mypy.ini                     # Configuraci√≥n de mypy
‚îú‚îÄ‚îÄ .env.example                 # Plantilla de variables de entorno
‚îî‚îÄ‚îÄ README.md                    # Este archivo
```

## üìö Fuentes de Datos

- **Precios de Combustibles:** [Secretar√≠a de Energ√≠a de Argentina](http://res1104.se.gob.ar/) - Datos hist√≥ricos desde 2022
- **Precio del Brent:** [Yahoo Finance](https://finance.yahoo.com/) (s√≠mbolo: BZ=F) - Precios diarios
- **Tipo de Cambio USD/ARS:** [Bluelytics API](https://bluelytics.com.ar/#!/api) - Cotizaciones oficial y blue

## üîß Tecnolog√≠as Utilizadas

- **Lenguaje:** Python 3.12
- **Gesti√≥n de dependencias:** Poetry
- **Base de datos:** PostgreSQL 15 (Alpine)
- **Contenedores:** Docker y Docker Compose
- **An√°lisis de datos:** pandas, numpy
- **Testing:** pytest, pytest-cov, pytest-mock
- **Type checking:** mypy
- **Formato de datos:** Parquet (PyArrow)

## üõ†Ô∏è Soluci√≥n de Problemas

### PostgreSQL no inicia

```bash
# Ver logs del contenedor
docker-compose logs postgres

# Verificar que el contenedor est√© corriendo
docker-compose ps

# Reiniciar contenedor
docker-compose restart postgres

# Reiniciar desde cero (ELIMINA TODOS LOS DATOS)
docker-compose down -v
docker-compose up -d
```

### Error de conexi√≥n a PostgreSQL

```bash
# Verificar que el contenedor est√© corriendo
docker-compose ps

# Probar conexi√≥n desde Python
poetry run python -c "from src.fuel_price.load import test_connection; print('OK' if test_connection() else 'ERROR')"

# Verificar variables de entorno
cat .env
```

### Problemas con dependencias de Python

```bash
# Reinstalar dependencias
poetry install --no-cache

# Actualizar Poetry
poetry self update

# Verificar versi√≥n de Python
python --version  # Debe ser 3.12+
```

### Error al extraer datos de la Secretar√≠a de Energ√≠a

Los archivos `.accdb` requieren procesamiento especial. El script `get_price_data_SE.py` maneja la conversi√≥n autom√°ticamente.

```bash
# Ejecutar extractor manualmente
poetry run python src/fuel_price/get_price_data_SE.py
```

## üìù Notas Importantes

- **Puerto:** PostgreSQL corre en el puerto **5432** (puerto est√°ndar)
- **Credenciales:** Las credenciales por defecto son:
  - Usuario: `fuel_user`
  - Contrase√±a: `fuel_password`
  - Base de datos: `fuel_prices_db`
- **Variables de entorno:** Configura el archivo `.env` para personalizar las credenciales
- **Vol√∫menes:** Los datos de PostgreSQL persisten en un volumen Docker llamado `postgres_data`
- **Schemas:** 
  - `staging`: Para datos crudos o m√≠nimamente procesados
  - `analytics`: Para datos agregados y transformados
- **Inicializaci√≥n autom√°tica:** El archivo `sql/init.sql` se ejecuta autom√°ticamente al crear el contenedor por primera vez
- **Reinicializar:** Para borrar todos los datos y empezar de cero: `docker-compose down -v && docker-compose up -d`
- **Datos:** Los archivos CSV en `data/raw/` est√°n en `.gitignore` y no se suben al repositorio
- **Context managers:** El c√≥digo usa context managers para manejar conexiones a la base de datos de forma segura

## ü§ñ Orquestaci√≥n con Apache Airflow

### Configuraci√≥n Inicial de Airflow

Airflow ya est√° instalado y configurado. Para iniciar Airflow:

```bash
# Opci√≥n 1: Modo standalone (webserver + scheduler en un solo proceso)
./start_airflow.sh

# Opci√≥n 2: Componentes separados (en terminales diferentes)
./start_webserver.sh   # Terminal 1: UI Web
./start_scheduler.sh   # Terminal 2: Scheduler
```

**Acceso a la UI:**
- URL: http://localhost:8080
- Usuario: `admin`
- Contrase√±a: `admin123`

### Configuraci√≥n de Airflow

Airflow est√° configurado con:
- **Base de datos:** PostgreSQL (misma instancia que los datos)
- **Ejecutor:** LocalExecutor (permite paralelismo)
- **DAGs folder:** `/dags`
- **Ejemplos:** Desactivados (`load_examples = False`)

### DAG del Pipeline ETL

El DAG `fuel_price_etl` ejecuta el pipeline completo diariamente a las 2 AM:

1. **Extract:** Descarga datos de APIs externas
2. **Transform:** Limpia y transforma los datos
3. **Load:** Carga a PostgreSQL

Para ejecutar manualmente desde la UI:
1. Ir a http://localhost:8080
2. Activar el DAG con el toggle
3. Clic en "Trigger DAG" para ejecutarlo inmediatamente

Para ejecutar desde la terminal:
```bash
export AIRFLOW_HOME=$PWD
poetry run airflow dags trigger fuel_price_etl
```

### Comandos √ötiles de Airflow

```bash
# Listar DAGs
export AIRFLOW_HOME=$PWD && poetry run airflow dags list

# Ver estado de un DAG
poetry run airflow dags state fuel_price_etl

# Ejecutar una tarea espec√≠fica
poetry run airflow tasks test fuel_price_etl extract 2024-01-01

# Ver logs de una tarea
poetry run airflow tasks logs fuel_price_etl extract 2024-01-01
```

### Configuraci√≥n de Airflow Variables

El DAG `fuel_price_etl` utiliza las siguientes variables opcionales que se pueden configurar desde la UI de Airflow para personalizar el comportamiento del pipeline:

| Variable | Tipo | Default | Descripci√≥n |
|----------|------|---------|-------------|
| `fuel_etl_update_all` | Boolean (JSON) | `true` | Si es `true`, actualiza todos los datos de combustibles desde la API. Si es `false`, solo actualiza datos incrementales |
| `fuel_etl_brent_start_date` | String | `"2022-01-01"` | Fecha de inicio (YYYY-MM-DD) para la extracci√≥n de precios de Brent desde Yahoo Finance |

**Para configurar en Airflow UI:**
1. Acceder a http://localhost:8080
2. Ir a **Admin** ‚Üí **Variables**
3. Hacer clic en **+** (Add a new record)
4. Ingresar los datos:
   - **Key:** `fuel_etl_update_all`
   - **Val:** `true` (marcar checkbox "Is JSON" si est√° disponible)
5. Repetir para otras variables

**Para configurar desde CLI:**
```bash
# Configurar update_all (Boolean JSON)
docker exec airflow_scheduler airflow variables set fuel_etl_update_all true --json

# Configurar fecha de inicio de Brent (String)
docker exec airflow_scheduler airflow variables set fuel_etl_brent_start_date "2023-01-01"

# Ver todas las variables configuradas
docker exec airflow_scheduler airflow variables list

# Ver una variable espec√≠fica
docker exec airflow_scheduler airflow variables get fuel_etl_update_all
```

**Notas:**
- Si no se configuran estas variables, el DAG usa los valores por defecto
- Los cambios en las variables se aplican en la **pr√≥xima ejecuci√≥n** del DAG
- Para aplicar cambios inmediatamente, dispara manualmente el DAG despu√©s de modificar las variables

## üìù Notas Importantes

- **Puerto:** PostgreSQL corre en el puerto **5432** (puerto est√°ndar)
- **Credenciales:** Las credenciales por defecto son:
  - Usuario: `fuel_user`
  - Contrase√±a: `fuel_password`
  - Base de datos: `fuel_prices_db`
- **Variables de entorno:** Configura el archivo `.env` para personalizar las credenciales
- **Vol√∫menes:** Los datos de PostgreSQL persisten en un volumen Docker llamado `postgres_data`
- **Schemas:** 
  - `staging`: Para datos crudos o m√≠nimamente procesados
  - `analytics`: Para datos agregados y transformados
- **Inicializaci√≥n autom√°tica:** El archivo `sql/init.sql` se ejecuta autom√°ticamente al crear el contenedor por primera vez
- **Reinicializar:** Para borrar todos los datos y empezar de cero: `docker-compose down -v && docker-compose up -d`
- **Datos:** Los archivos CSV en `data/raw/` est√°n en `.gitignore` y no se suben al repositorio
- **Context managers:** El c√≥digo usa context managers para manejar conexiones a la base de datos de forma segura

## üë§ Autor

Sebastian J. Castro - [GitHub](https://github.com/sebacastrocba)

## üìÑ Licencia

Este proyecto es de c√≥digo abierto y est√° disponible bajo la licencia MIT.
